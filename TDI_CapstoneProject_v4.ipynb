{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation: library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from scipy.misc import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import base\n",
    "\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords');\n",
    "nltk.download('punkt');\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['the','i','you','a','c','slu','amazon','google','apple','microsoft','company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    '''\n",
    "    INPUT: a single user comment, eg. 'Work hard, have fun, make history. Be proud of our self, the job we are doing.'\n",
    "    OUTPUT: tokenized comment (i.e, single words), eg. ['work','hard','have','fun', 'make','history',...]\n",
    "    \n",
    "    NOTE:\n",
    "    nltk.sent_tokenize: this gives a list of sentences\n",
    "    nltk.word_tokenize: this gives a list of sentences\n",
    "    '''\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word.lower() not in stopwords]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('^[a-z|A-Z]+$', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump\n",
    "keyword = open(\"Keyword.pkl\",\"wb\")\n",
    "pickle.dump(KW_dict,keyword)\n",
    "keyword.close()\n",
    "\n",
    "topic = open(\"Topic.pkl\",\"wb\")\n",
    "pickle.dump(Topic_dict,topic)\n",
    "topic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_s = open(\"Keyword_s.pkl\",\"wb\")\n",
    "pickle.dump(KW_dict_s,keyword_s)\n",
    "keyword_s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "KW_dict = pickle.load(open(\"Keyword.pkl\", \"rb\"))\n",
    "\n",
    "Topic_dict = pickle.load(open(\"Topic.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amazing balance benefits best culture environment food free free food good great life nice opportunities pay people perks place salary smart smart people work working'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KW_dict['google']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic 0: work culture',\n",
       " 'Topic 1: good pay',\n",
       " 'Topic 2: people get',\n",
       " 'Topic 3: benefits great']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Topic_dict['amazon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the table is 122249 rows and 18 columns.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'./all_company.csv')\n",
    "print('The dimension of the table is ' + str(df.shape[0]) + ' rows and ' + str(df.shape[1]) + ' columns.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list=df.groupby('Company').count().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.extend(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ViolinPlots, Keyword, WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_Violin(target_company, df):\n",
    "    '''\n",
    "    Input: target_company => 'google'\n",
    "    Output: text_pros, violinplots(save into file)\n",
    "    '''\n",
    "    # filter dataframe\n",
    "    df_t=df.loc[df['Company'] == target_company]\n",
    "    df_t=df_t.rename(columns={'rating_overall':'Overall', \"rating_balance\":\"Work-Life Balance\", \n",
    "                         \"rating_culture\": \"Culture\",\"rating_career\":\"Career\", \n",
    "                          \"rating_comp\":\"Compensation\",\"rating_mgmt\":\"Management\"})\n",
    "    \n",
    "    \n",
    "    # Violin plot\n",
    "    #plt.clf()\n",
    "    sns.set(rc={'figure.figsize':(18,6)});\n",
    "    Vplot = sns.violinplot(data=df_t[['Overall','Work-Life Balance','Culture','Career',\n",
    "                                  'Compensation','Management']],palette='Set3');\n",
    "    Vplot.set_title(target_company.capitalize()+' Ratings Plot', fontsize=30);\n",
    "    Vplot.set(xlabel='Ratings', ylabel='Stars');\n",
    "    Vplot.set_xlabel('Ratings', fontsize=20);\n",
    "    Vplot.set_ylabel('Stars', fontsize=20);\n",
    "    Vplot.figure.savefig(r'./ViolinPlots/{}_Violin.jpg'.format(target_company));\n",
    "    plt.clf()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(company_list)):\n",
    "    get_Violin(company_list[i],df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nKW_dict = {}\\nfor i in range(len(company_list)):\\n    KW_dict[company_list[i]]=get_keyword(company_list[i],df)\\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ViolinPlots & Keyword_dict\n",
    "def get_keyword(target_company, df):\n",
    "    '''\n",
    "    Input: target_company => 'google'\n",
    "    Output: text_pros, violinplots(save into file)\n",
    "    '''\n",
    "    # filter dataframe\n",
    "    df_t=df.loc[df['Company'] == target_company]\n",
    "    \n",
    "    '''\n",
    "    # Violin plot\n",
    "    sns.set(rc={'figure.figsize':(18,6)});\n",
    "    Vplot = sns.violinplot(data=df_t[['rating_overall','rating_balance','rating_culture','rating_career',\n",
    "                                  'rating_comp','rating_mgmt']],palette='Set3');\n",
    "    Vplot.set_title(target_company.capitalize()+' Ratings Plot', fontsize=30);\n",
    "    Vplot.set(xlabel='Ratings', ylabel='Stars');\n",
    "    Vplot.set_xlabel('Ratings', fontsize=20,fontname=\"Arial\");\n",
    "    Vplot.set_ylabel('Stars', fontsize=20, fontname=\"Arial\");\n",
    "    Vplot.figure.savefig(r'./ViolinPlots/{}_Violin.jpg'.format(target_company));\n",
    "    plt.clf()\n",
    "    '''\n",
    "    \n",
    "    # feature words of pros\n",
    "    def get_pros(df_company):\n",
    "        pros = []\n",
    "        for i in range(len(df_company)):  \n",
    "            pros.append(df_company.iloc[i][9])\n",
    "        return pros\n",
    "    \n",
    "    pros = get_pros(df_t)\n",
    "    \n",
    "    tfidf_model = TfidfVectorizer(max_df=0.75, max_features=100,\n",
    "                                 min_df=0.05, stop_words=stopwords,\n",
    "                                 use_idf=True, tokenizer=tokenization, ngram_range=(1,2))\n",
    "    tfidf_matrix = tfidf_model.fit_transform(pros)\n",
    "    feature_pros = tfidf_model.get_feature_names()\n",
    "    text_pros = ' '.join(feature_pros)\n",
    "    \n",
    "    return text_pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KW_dict = {}\n",
    "for i in range(len(company_list)):\n",
    "    KW_dict[company_list[i]]=get_keyword(company_list[i],df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "KW_dict_s = {}\n",
    "company_list_s = ['google','amazon','point72','microsoft','apple', 'accenture', 'airbnb','altria',\n",
    "               'boeing','broadcom','capitalone','citi','comcast','deloitte','dupont','facebook','honeywell','intel',\n",
    "                'lyft','netflix','nike','pfizer','target','uber','visa','verizon','linkedin','bayer','chevron']\n",
    "for i in range(len(company_list_s)):\n",
    "    KW_dict_s[company_list_s[i]]=get_keyword(company_list_s[i],df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordClouds\n",
    "for k, v in KW_dict.items():\n",
    "    config = Path(r'./Masks/mask_{}.png'.format(k))\n",
    "    if config.is_file():\n",
    "        mask = imread(r'./Masks/mask_{}.png'.format(k))\n",
    "        wc=WordCloud(mask=mask,background_color=\"white\",scale=2,repeat=True,colormap = 'viridis').generate(v)\n",
    "        wc.to_file(r'./WordClouds/{}_wordcloud.jpg'.format(k))\n",
    "    else:\n",
    "        mask = imread(r'./Masks/mask.png'.format(k))\n",
    "        wc=WordCloud(mask=mask,background_color=\"white\",scale=2,repeat=True,colormap = 'viridis').generate(v)\n",
    "        wc.to_file(r'./WordClouds/{}_wordcloud.jpg'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(target_company, df):\n",
    "    '''\n",
    "    Input: target_company\n",
    "    Output: first 4 topic of each company\n",
    "    '''\n",
    "    class ReviewTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "        def __init__(self, target_company):\n",
    "            self.name = target_company  # We will need these in transform()\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            # This transformer doesn't need to learn anything about the data,\n",
    "            # so it can just return self without any further processing\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            # Return an array with the same number of rows as X and one\n",
    "            # column for each in self.col_names\n",
    "\n",
    "            X_t=X.loc[X['Company'] == self.name]\n",
    "\n",
    "            pros = []\n",
    "            for i in range(len(X_t)):  \n",
    "                pros.append(X_t.iloc[i][9])\n",
    "            return pros\n",
    "        \n",
    "    CntVec = CountVectorizer(max_df=0.75, min_df=0.05, max_features=100, \n",
    "                             stop_words=stopwords, tokenizer=tokenization, ngram_range=(1,2))\n",
    "    \n",
    "    LDA = LatentDirichletAllocation(n_components=4, max_iter=5, learning_method='online', \n",
    "                                    learning_offset=50.,random_state=0)\n",
    "    \n",
    "    lda_est = Pipeline([('GetProsCmt', ReviewTransformer(target_company)),\n",
    "                        ('CountVectorizer', CntVec),\n",
    "                        ('LatentDirichletAllocation', LDA)])\n",
    "    \n",
    "    model = lda_est.fit(df)\n",
    "    \n",
    "    def display_topics(model, feature_names, no_top_words):\n",
    "        res = []\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            topic_words = \" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "            elm = \"Topic {}: {}\".format(topic_idx, topic_words)\n",
    "            res.append(elm)\n",
    "            #print(elm)\n",
    "        return res\n",
    "    \n",
    "    topics = display_topics(lda_est.named_steps['LatentDirichletAllocation'], \n",
    "                            lda_est.named_steps['CountVectorizer'].get_feature_names(), 2)\n",
    "    return topics,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_company = 'google'\n",
    "Topic,model=get_topic(target_company,df)\n",
    "dill.dump(model, open(r'./TopicModel/{}_TopicModel.joblib'.format(target_company), 'wb'))\n",
    "\n",
    "lda_est = model\n",
    "step1 = lda_est.named_steps['GetProsCmt'].fit_transform(df)\n",
    "step2 = lda_est.named_steps['CountVectorizer'].fit_transform(step1)\n",
    "step3 = lda_est.named_steps['LatentDirichletAllocation'].fit(step2)\n",
    "topic_plot = pyLDAvis.sklearn.prepare(step3, step2, lda_est.named_steps['CountVectorizer'])\n",
    "pyLDAvis.save_html(topic_plot, r'./LDA_plot/{}.html'.format(target_company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic_dict = {}\n",
    "for i in range(len(company_list)):\n",
    "    target_company = company_list[i]\n",
    "    Topic_dict[company_list[i]],model=get_topic(company_list[i],df)\n",
    "    dill.dump(model, open(r'./TopicModel/{}_TopicModel.joblib'.format(target_company), 'wb'))\n",
    "    \n",
    "    \n",
    "    lda_est = model\n",
    "    step1 = lda_est.named_steps['GetProsCmt'].fit_transform(df)\n",
    "    step2 = lda_est.named_steps['CountVectorizer'].fit_transform(step1)\n",
    "    step3 = lda_est.named_steps['LatentDirichletAllocation'].fit(step2)\n",
    "    topic_plot = pyLDAvis.sklearn.prepare(step3, step2, lda_est.named_steps['CountVectorizer'])\n",
    "    pyLDAvis.save_html(topic_plot, r'./LDA_plot/{}.html'.format(target_company))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic_dict['amazon'] # type list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(model, open(r'./TopicModel/{}_TopicModel.joblib'.format(target_company), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_est = dill.load(open(r'./TopicModel/{}_TopicModel.joblib'.format(target_company), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "from __future__ import print_function\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = lda_est.named_steps['GetProsCmt'].fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2 = lda_est.named_steps['CountVectorizer'].fit_transform(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3 = lda_est.named_steps['LatentDirichletAllocation'].fit(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el195751401778289224965448106631\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el195751401778289224965448106631_data = {\"mdsDat\": {\"x\": [-0.12425344329870834, -0.23292543946586006, 0.09548293369813937, 0.2616959490664289], \"y\": [0.1763254795601991, -0.1882908339893342, 0.15089048234511288, -0.13892512791597772], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [31.413185899508495, 24.56915936080209, 22.919170660821294, 21.098484078868125]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [549.0, 570.0, 469.0, 264.0, 188.0, 174.0, 280.0, 222.0, 300.0, 109.0, 700.0, 108.0, 110.0, 134.0, 120.0, 112.0, 107.0, 129.0, 144.0, 111.0, 92.0, 99.0, 235.0, 91.56599663475822, 111.35165729221475, 118.23656587627298, 131.45003670254508, 548.074694735487, 94.455281897824, 324.63484664444667, 59.798010908437796, 55.83864041292371, 25.219433345531954, 44.642203613246366, 31.72780687100771, 23.636756665329703, 4.059973803605489, 3.008771800108789, 4.043498366022138, 0.8104358195556204, 1.5941909744938345, 0.6776479638828345, 0.48174207073366165, 0.7311230542524155, 0.7189495001052397, 0.39173022197258445, 108.10092249814558, 99.34937516568579, 496.76685344531273, 107.16871115663808, 212.29729808910773, 115.14758800770012, 138.80456486413257, 18.914344904709335, 2.23390943619474, 1.2668649670928418, 0.9882995275147601, 1.1372960396798586, 2.3571507798355347, 1.0042619156184602, 1.3659003782222867, 0.4053051080949392, 0.34350452618008426, 0.3169091536346335, 0.3387310564750141, 1.658345072954252, 1.0446983083937842, 0.38159899554732396, 0.35498487635290416, 172.45043626003962, 106.16075867658407, 242.0844437401931, 224.12025209921956, 51.58744175726546, 231.94595265033865, 121.46886022575963, 54.818739900627456, 3.4732799465471813, 1.3345631088610448, 6.0443729966148885, 1.5695079859192282, 0.8822660595371659, 0.6491305136594598, 0.5938014080705887, 0.5778044354931866, 0.39056704110288143, 0.471725277214838, 0.3814908787499764, 0.34998768134777963, 1.307111038375351, 0.6357292984874889, 0.3562986012402817, 107.956835868213, 185.55822695877205, 84.67892994158834, 166.21737674101018, 343.38862382174665, 87.68889259095718, 20.854190472650796, 43.01843303372876, 22.115252848833528, 28.261035780497004, 3.7954137998233892, 6.117136168849524, 14.770989010972807, 1.0857975647042608, 1.193238420600319, 2.307385288687737, 5.152058256604483, 0.3735226120117353, 0.42156067787553747, 0.4006699925344642, 0.3617307540013545, 0.33916689245624854, 0.39159747365004977], \"Term\": [\"good\", \"work\", \"people\", \"food\", \"smart\", \"free\", \"perks\", \"environment\", \"benefits\", \"smart people\", \"great\", \"free food\", \"salary\", \"place\", \"balance\", \"best\", \"pay\", \"nice\", \"working\", \"amazing\", \"life\", \"opportunities\", \"culture\", \"life\", \"best\", \"balance\", \"place\", \"work\", \"opportunities\", \"great\", \"culture\", \"environment\", \"amazing\", \"benefits\", \"perks\", \"good\", \"pay\", \"working\", \"people\", \"salary\", \"food\", \"nice\", \"free food\", \"free\", \"smart\", \"smart people\", \"salary\", \"pay\", \"good\", \"nice\", \"benefits\", \"culture\", \"great\", \"food\", \"working\", \"free food\", \"amazing\", \"place\", \"perks\", \"balance\", \"free\", \"best\", \"opportunities\", \"life\", \"smart people\", \"work\", \"people\", \"smart\", \"environment\", \"free\", \"free food\", \"food\", \"perks\", \"working\", \"great\", \"people\", \"culture\", \"pay\", \"opportunities\", \"work\", \"smart\", \"amazing\", \"smart people\", \"best\", \"nice\", \"life\", \"balance\", \"salary\", \"place\", \"good\", \"benefits\", \"environment\", \"smart people\", \"smart\", \"amazing\", \"environment\", \"people\", \"working\", \"nice\", \"benefits\", \"perks\", \"good\", \"opportunities\", \"culture\", \"work\", \"salary\", \"place\", \"food\", \"great\", \"life\", \"best\", \"pay\", \"free food\", \"balance\", \"free\"], \"Total\": [549.0, 570.0, 469.0, 264.0, 188.0, 174.0, 280.0, 222.0, 300.0, 109.0, 700.0, 108.0, 110.0, 134.0, 120.0, 112.0, 107.0, 129.0, 144.0, 111.0, 92.0, 99.0, 235.0, 92.64699544150749, 112.77232448625581, 120.05171996156253, 134.13055884417304, 570.548401816029, 99.92876333268852, 700.5374224155224, 235.88147498561491, 222.76730063152706, 111.76892887417222, 300.59366403457034, 280.3204625988963, 549.9717569295148, 107.28329890837291, 144.5190155845262, 469.9456807219222, 110.37864676115544, 264.900364908084, 129.2783540286649, 108.27109646841193, 174.9390571661644, 188.22828344034386, 109.33642766032007, 110.37864676115544, 107.28329890837291, 549.9717569295148, 129.2783540286649, 300.59366403457034, 235.88147498561491, 700.5374224155224, 264.900364908084, 144.5190155845262, 108.27109646841193, 111.76892887417222, 134.13055884417304, 280.3204625988963, 120.05171996156253, 174.9390571661644, 112.77232448625581, 99.92876333268852, 92.64699544150749, 109.33642766032007, 570.548401816029, 469.9456807219222, 188.22828344034386, 222.76730063152706, 174.9390571661644, 108.27109646841193, 264.900364908084, 280.3204625988963, 144.5190155845262, 700.5374224155224, 469.9456807219222, 235.88147498561491, 107.28329890837291, 99.92876333268852, 570.548401816029, 188.22828344034386, 111.76892887417222, 109.33642766032007, 112.77232448625581, 129.2783540286649, 92.64699544150749, 120.05171996156253, 110.37864676115544, 134.13055884417304, 549.9717569295148, 300.59366403457034, 222.76730063152706, 109.33642766032007, 188.22828344034386, 111.76892887417222, 222.76730063152706, 469.9456807219222, 144.5190155845262, 129.2783540286649, 300.59366403457034, 280.3204625988963, 549.9717569295148, 99.92876333268852, 235.88147498561491, 570.548401816029, 110.37864676115544, 134.13055884417304, 264.900364908084, 700.5374224155224, 92.64699544150749, 112.77232448625581, 107.28329890837291, 108.27109646841193, 120.05171996156253, 174.9390571661644], \"loglift\": [23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1462, 1.1453, 1.1427, 1.1378, 1.1178, 1.1016, 0.3888, -0.2144, -0.2257, -0.3309, -0.7491, -1.0208, -1.9891, -2.1164, -2.7139, -3.5976, -3.7562, -3.955, -4.0932, -4.257, -4.3197, -4.4097, -4.4737, 1.3828, 1.3268, 1.3019, 1.2161, 1.0559, 0.6866, -0.2151, -1.2358, -2.766, -3.0444, -3.3245, -3.3665, -3.3748, -3.38, -3.4489, -4.2248, -4.2693, -4.2743, -4.3733, -4.4371, -4.7052, -4.7974, -5.0381, 1.4589, 1.4535, 1.3831, 1.2494, 0.4431, 0.3679, 0.1202, 0.0139, -1.9572, -2.8427, -3.0743, -3.3137, -3.3685, -3.6534, -3.7734, -3.9373, -3.9958, -4.0661, -4.1944, -4.4755, -4.5689, -4.6855, -4.9649, 1.5433, 1.5417, 1.2784, 1.2631, 1.2422, 1.0564, -0.2684, -0.3882, -0.9837, -1.4124, -1.7147, -2.0963, -2.098, -3.0656, -3.1662, -3.1873, -3.3565, -3.9576, -4.0332, -4.0341, -4.1455, -4.3132, -4.546], \"logprob\": [23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.9078, -2.7122, -2.6522, -2.5462, -1.1184, -2.8767, -1.6422, -3.3339, -3.4024, -4.1972, -3.6262, -3.9677, -4.262, -6.0237, -6.3233, -6.0277, -7.635, -6.9585, -7.814, -8.1552, -7.738, -7.7548, -8.362, -2.4961, -2.5805, -0.971, -2.5047, -1.8211, -2.4329, -2.246, -4.2392, -6.3754, -6.9426, -7.1909, -7.0505, -6.3217, -7.1749, -6.8673, -8.0822, -8.2477, -8.3283, -8.2617, -6.6733, -7.1354, -8.1425, -8.2148, -1.9595, -2.4446, -1.6203, -1.6974, -3.1663, -1.6631, -2.3099, -3.1056, -5.8645, -6.821, -5.3105, -6.6588, -7.2349, -7.5417, -7.6308, -7.6581, -8.0498, -7.861, -8.0733, -8.1595, -6.8418, -7.5626, -8.1416, -2.3451, -1.8035, -2.588, -1.9135, -1.188, -2.553, -3.9893, -3.2652, -3.9306, -3.6853, -5.693, -5.2157, -4.3342, -6.9445, -6.8502, -6.1907, -5.3874, -8.0116, -7.8906, -7.9414, -8.0437, -8.1081, -7.9643]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 1, 2, 3, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 4, 1, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], \"Freq\": [0.2236757590129957, 0.008947030360519827, 0.008947030360519827, 0.7604975806441854, 0.9829096995676577, 0.008329743216675066, 0.14970375421760285, 0.7052710198695956, 0.0033267500937245076, 0.1430502540301538, 0.9842840475770116, 0.008867423852045149, 0.25436503652378406, 0.48753298667058614, 0.23316795014680208, 0.025436503652378407, 0.2513833935287835, 0.745172202246037, 0.007550008474672984, 0.07172508050939334, 0.9135510254354311, 0.007550008474672984, 0.005716276377608223, 0.005716276377608223, 0.9831995369486143, 0.009236075301885853, 0.9790239819999004, 0.04363860452396991, 0.9036827686838768, 0.0018182751884987462, 0.05091170527796489, 0.4639295340987892, 0.1984190930453283, 0.33117431357205873, 0.00713737744767368, 0.9930165523617442, 0.007735246998722385, 0.8276714288632951, 0.007735246998722385, 0.1624401869731701, 0.9406701020310825, 0.010007128745011515, 0.04002851498004606, 0.03728446124141155, 0.9227904157249359, 0.02796334593105866, 0.00851162201098491, 0.0021279055027462277, 0.25747656583229356, 0.729871587441956, 0.11415506275682777, 0.0071346914223017355, 0.7990854392977944, 0.07848160564531909, 0.976660360836862, 0.007455422601808107, 0.007455422601808107, 0.009059723319165758, 0.9784501184699019, 0.009059723319165758, 0.005312697867305022, 0.010625395734610044, 0.988161803318734, 0.009146082613076959, 0.9877769222123115, 0.9604794234034159, 0.003505399355486919, 0.010516198066460758, 0.026290495166151895, 0.020758513942723072, 0.013839009295148716, 0.3598142416738666, 0.6089164089865435], \"Term\": [\"amazing\", \"amazing\", \"amazing\", \"amazing\", \"balance\", \"balance\", \"benefits\", \"benefits\", \"benefits\", \"benefits\", \"best\", \"best\", \"culture\", \"culture\", \"culture\", \"culture\", \"environment\", \"environment\", \"food\", \"food\", \"food\", \"food\", \"free\", \"free\", \"free\", \"free food\", \"free food\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"life\", \"nice\", \"nice\", \"nice\", \"nice\", \"opportunities\", \"opportunities\", \"opportunities\", \"pay\", \"pay\", \"pay\", \"people\", \"people\", \"people\", \"people\", \"perks\", \"perks\", \"perks\", \"perks\", \"place\", \"place\", \"place\", \"salary\", \"salary\", \"salary\", \"smart\", \"smart\", \"smart\", \"smart people\", \"smart people\", \"work\", \"work\", \"work\", \"work\", \"working\", \"working\", \"working\", \"working\"]}, \"R\": 23, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el195751401778289224965448106631\", ldavis_el195751401778289224965448106631_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el195751401778289224965448106631\", ldavis_el195751401778289224965448106631_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el195751401778289224965448106631\", ldavis_el195751401778289224965448106631_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.124253  0.176325       1        1  31.413186\n",
       "3     -0.232925 -0.188291       2        1  24.569159\n",
       "1      0.095483  0.150890       3        1  22.919171\n",
       "2      0.261696 -0.138925       4        1  21.098484, topic_info=     Category        Freq           Term       Total  loglift  logprob\n",
       "term                                                                  \n",
       "9     Default  549.000000           good  549.000000  23.0000  23.0000\n",
       "21    Default  570.000000           work  570.000000  22.0000  22.0000\n",
       "15    Default  469.000000         people  469.000000  21.0000  21.0000\n",
       "6     Default  264.000000           food  264.000000  20.0000  20.0000\n",
       "19    Default  188.000000          smart  188.000000  19.0000  19.0000\n",
       "7     Default  174.000000           free  174.000000  18.0000  18.0000\n",
       "16    Default  280.000000          perks  280.000000  17.0000  17.0000\n",
       "5     Default  222.000000    environment  222.000000  16.0000  16.0000\n",
       "2     Default  300.000000       benefits  300.000000  15.0000  15.0000\n",
       "20    Default  109.000000   smart people  109.000000  14.0000  14.0000\n",
       "10    Default  700.000000          great  700.000000  13.0000  13.0000\n",
       "8     Default  108.000000      free food  108.000000  12.0000  12.0000\n",
       "18    Default  110.000000         salary  110.000000  11.0000  11.0000\n",
       "17    Default  134.000000          place  134.000000  10.0000  10.0000\n",
       "1     Default  120.000000        balance  120.000000   9.0000   9.0000\n",
       "3     Default  112.000000           best  112.000000   8.0000   8.0000\n",
       "14    Default  107.000000            pay  107.000000   7.0000   7.0000\n",
       "12    Default  129.000000           nice  129.000000   6.0000   6.0000\n",
       "22    Default  144.000000        working  144.000000   5.0000   5.0000\n",
       "0     Default  111.000000        amazing  111.000000   4.0000   4.0000\n",
       "11    Default   92.000000           life   92.000000   3.0000   3.0000\n",
       "13    Default   99.000000  opportunities   99.000000   2.0000   2.0000\n",
       "4     Default  235.000000        culture  235.000000   1.0000   1.0000\n",
       "11     Topic1   91.565997           life   92.646995   1.1462  -2.9078\n",
       "3      Topic1  111.351657           best  112.772324   1.1453  -2.7122\n",
       "1      Topic1  118.236566        balance  120.051720   1.1427  -2.6522\n",
       "17     Topic1  131.450037          place  134.130559   1.1378  -2.5462\n",
       "21     Topic1  548.074695           work  570.548402   1.1178  -1.1184\n",
       "13     Topic1   94.455282  opportunities   99.928763   1.1016  -2.8767\n",
       "10     Topic1  324.634847          great  700.537422   0.3888  -1.6422\n",
       "...       ...         ...            ...         ...      ...      ...\n",
       "11     Topic3    0.390567           life   92.646995  -3.9958  -8.0498\n",
       "1      Topic3    0.471725        balance  120.051720  -4.0661  -7.8610\n",
       "18     Topic3    0.381491         salary  110.378647  -4.1944  -8.0733\n",
       "17     Topic3    0.349988          place  134.130559  -4.4755  -8.1595\n",
       "9      Topic3    1.307111           good  549.971757  -4.5689  -6.8418\n",
       "2      Topic3    0.635729       benefits  300.593664  -4.6855  -7.5626\n",
       "5      Topic3    0.356299    environment  222.767301  -4.9649  -8.1416\n",
       "20     Topic4  107.956836   smart people  109.336428   1.5433  -2.3451\n",
       "19     Topic4  185.558227          smart  188.228283   1.5417  -1.8035\n",
       "0      Topic4   84.678930        amazing  111.768929   1.2784  -2.5880\n",
       "5      Topic4  166.217377    environment  222.767301   1.2631  -1.9135\n",
       "15     Topic4  343.388624         people  469.945681   1.2422  -1.1880\n",
       "22     Topic4   87.688893        working  144.519016   1.0564  -2.5530\n",
       "12     Topic4   20.854190           nice  129.278354  -0.2684  -3.9893\n",
       "2      Topic4   43.018433       benefits  300.593664  -0.3882  -3.2652\n",
       "16     Topic4   22.115253          perks  280.320463  -0.9837  -3.9306\n",
       "9      Topic4   28.261036           good  549.971757  -1.4124  -3.6853\n",
       "13     Topic4    3.795414  opportunities   99.928763  -1.7147  -5.6930\n",
       "4      Topic4    6.117136        culture  235.881475  -2.0963  -5.2157\n",
       "21     Topic4   14.770989           work  570.548402  -2.0980  -4.3342\n",
       "18     Topic4    1.085798         salary  110.378647  -3.0656  -6.9445\n",
       "17     Topic4    1.193238          place  134.130559  -3.1662  -6.8502\n",
       "6      Topic4    2.307385           food  264.900365  -3.1873  -6.1907\n",
       "10     Topic4    5.152058          great  700.537422  -3.3565  -5.3874\n",
       "11     Topic4    0.373523           life   92.646995  -3.9576  -8.0116\n",
       "3      Topic4    0.421561           best  112.772324  -4.0332  -7.8906\n",
       "14     Topic4    0.400670            pay  107.283299  -4.0341  -7.9414\n",
       "8      Topic4    0.361731      free food  108.271096  -4.1455  -8.0437\n",
       "1      Topic4    0.339167        balance  120.051720  -4.3132  -8.1081\n",
       "7      Topic4    0.391597           free  174.939057  -4.5460  -7.9643\n",
       "\n",
       "[115 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "0         1  0.223676       amazing\n",
       "0         2  0.008947       amazing\n",
       "0         3  0.008947       amazing\n",
       "0         4  0.760498       amazing\n",
       "1         1  0.982910       balance\n",
       "1         2  0.008330       balance\n",
       "2         1  0.149704      benefits\n",
       "2         2  0.705271      benefits\n",
       "2         3  0.003327      benefits\n",
       "2         4  0.143050      benefits\n",
       "3         1  0.984284          best\n",
       "3         3  0.008867          best\n",
       "4         1  0.254365       culture\n",
       "4         2  0.487533       culture\n",
       "4         3  0.233168       culture\n",
       "4         4  0.025437       culture\n",
       "5         1  0.251383   environment\n",
       "5         4  0.745172   environment\n",
       "6         1  0.007550          food\n",
       "6         2  0.071725          food\n",
       "6         3  0.913551          food\n",
       "6         4  0.007550          food\n",
       "7         1  0.005716          free\n",
       "7         2  0.005716          free\n",
       "7         3  0.983200          free\n",
       "8         2  0.009236     free food\n",
       "8         3  0.979024     free food\n",
       "9         1  0.043639          good\n",
       "9         2  0.903683          good\n",
       "9         3  0.001818          good\n",
       "...     ...       ...           ...\n",
       "14        1  0.037284           pay\n",
       "14        2  0.922790           pay\n",
       "14        3  0.027963           pay\n",
       "15        1  0.008512        people\n",
       "15        2  0.002128        people\n",
       "15        3  0.257477        people\n",
       "15        4  0.729872        people\n",
       "16        1  0.114155         perks\n",
       "16        2  0.007135         perks\n",
       "16        3  0.799085         perks\n",
       "16        4  0.078482         perks\n",
       "17        1  0.976660         place\n",
       "17        2  0.007455         place\n",
       "17        4  0.007455         place\n",
       "18        1  0.009060        salary\n",
       "18        2  0.978450        salary\n",
       "18        4  0.009060        salary\n",
       "19        1  0.005313         smart\n",
       "19        3  0.010625         smart\n",
       "19        4  0.988162         smart\n",
       "20        3  0.009146  smart people\n",
       "20        4  0.987777  smart people\n",
       "21        1  0.960479          work\n",
       "21        2  0.003505          work\n",
       "21        3  0.010516          work\n",
       "21        4  0.026290          work\n",
       "22        1  0.020759       working\n",
       "22        2  0.013839       working\n",
       "22        3  0.359814       working\n",
       "22        4  0.608916       working\n",
       "\n",
       "[73 rows x 3 columns], R=23, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_plot = pyLDAvis.sklearn.prepare(step3, step2, lda_est.named_steps['CountVectorizer'])\n",
    "topic_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(topic_plot, r'./LDA_plot/{}.html'.format(target_company))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: New Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(user_prf, KW_dict):\n",
    "    \n",
    "    def stopword_RMV(sent):\n",
    "        res = []\n",
    "        for word in sent.split():\n",
    "            if word.lower() not in stopwords:\n",
    "                res.append(word)\n",
    "        return ' '.join(res)\n",
    "    \n",
    "    doc0 = nlp(stopword_RMV(user_prf))\n",
    "    score_dict = {}\n",
    "    for k,v in KW_dict.items():\n",
    "        temp_doc = nlp(v)\n",
    "        score_dict[k]= doc0.similarity(temp_doc)\n",
    "        \n",
    "    sorted_score = sorted(score_dict.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    \n",
    "    rcm_company = []\n",
    "    for i in range(5):\n",
    "        rcm_company.append('#'+str(i+1)+': '+str(sorted_score[i][0].capitalize()))\n",
    "\n",
    "    return rcm_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Preference:free food\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#1: Mcdonald', '#2: Google', '#3: Netflix', '#4: Facebook', '#5: Point72']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcm_company=get_recommendation(input('Your Preference:'),KW_dict_s)\n",
    "rcm_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
